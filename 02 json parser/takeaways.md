# Takeaways

## Lexical Analysis and Syntax Analysis(Parsing)

### Lexical Analysis

Lexical analysis is the first phase of a compiler. It takes the raw input and converts it into tokens. A token is a sequence of characters that represent a unit of meaning. For example, the string `int x = 5;` can be broken down into the following tokens:

`[INT, IDENTIFIER("x"), ASSIGN, Integer(5), SEMICOLON]`

**Source Code** -> **Tokens** -> **Abstract Syntax Tree**

Tokens are the smallest unit of meaning in a programming language. They are used to build an abstract syntax tree (AST) which represents the structure of the program. The AST is then used by the parser to generate the intermediate representation (IR) of the program.

**Note:** Whitespace acts as a delimiter between tokens. It is ignored by the parser.

### Syntax Analysis

Syntax analysis is the second phase of a compiler. It takes the tokens generated by the lexer and checks if they form a valid program according to the grammar of the language. The grammar of a language defines the rules for constructing valid programs.

It's the process of analyzing the list of tokens to match the grammar of the language. It's also known as parsing.

letâ€™s say we are using JavaScript, have a MagicLexer, a MagicParser and the AST is built
out of JavaScript objects, then the parsing step might produce something like this:

```javascript
> var input = 'if (3 * 5 > 10) { return "hello"; } else { return "goodbye"; }';
> var tokens = MagicLexer.parse(input);
> MagicParser.parse(tokens);
{
  type: 'Program',
  body: [
    {
      type: 'IfStatement',
      test: {
        type: 'BinaryExpression',
        operator: '>',
        left: {
          type: 'BinaryExpression',
          operator: '*',
          left: { type: 'Literal', value: 3 },
          right: { type: 'Literal', value: 5 }
        },
        right: { type: 'Literal', value: 10 }
      },
      consequent: {
        type: 'BlockStatement',
        body: [
          { type: 'ReturnStatement', argument: { type: 'Literal', value: 'hello' } }
        ]
      },
      alternate: {
        type: 'BlockStatement',
        body: [
          { type: 'ReturnStatement', argument: { type: 'Literal', value: 'goodbye' } }
        ]
      }
    }
  ]
}
```

So, this what parsers do, they take source code as input (either as text or tokens) and produce a data structure that represents the program. This data structure is then used by the compiler to generate the output (e.g., machine code).

### Parsing Techniques

There are two main parsing techniques used in compilers:

1. **Top-Down Parsing**: In top-down parsing, the parser starts at the root of the parse tree and works its way down to the leaves. It uses a set of rules to determine which production to apply next. Examples of top-down parsers include LL parsers and recursive descent parsers.

2. **Bottom-Up Parsing**: In bottom-up parsing, the parser starts at the leaves of the parse tree and works its way up to the root. It uses a set of rules to determine which production to apply next. Examples of bottom-up parsers include LR parsers and LALR parsers.
